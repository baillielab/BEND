{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from bend.models.hyena_dna import HyenaDNAPreTrainedModel, CharacterTokenizer\n",
    "import os\n",
    "from utils import generate_random_dna_sequence, get_device, remove_special_tokens_and_padding\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "WORK_PATH = '../../'\n",
    "EMBEDDER_DIR = os.path.join(WORK_PATH, 'pretrained_models', 'hyenadna')\n",
    "EMBEDDER_NAME = 'hyenadna-tiny-1k-seqlen'\n",
    "EMBEDDER_PATH = os.path.join(EMBEDDER_DIR, EMBEDDER_NAME)\n",
    "\n",
    "PADDING_VALUE = -100\n",
    "\n",
    "MAX_LENGTHS = {\n",
    "    \"hyenadna-tiny-1k-seqlen\": 1024,\n",
    "    \"hyenadna-small-32k-seqlen\": 32768,\n",
    "    \"hyenadna-medium-160k-seqlen\": 160000,\n",
    "    \"hyenadna-medium-450k-seqlen\": 450000,\n",
    "    \"hyenadna-large-1m-seqlen\": 1_000_000,\n",
    "}\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f38af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CharacterTokenizer(\n",
    "    characters=[\"A\", \"C\", \"G\", \"T\", \"N\"],  # add DNA characters, N is uncertain\n",
    "    model_max_length=MAX_LENGTHS[EMBEDDER_NAME]\n",
    "    + 2,  # to account for special tokens, like EOS\n",
    "    add_special_tokens=False,  # we handle special tokens elsewhere\n",
    "    padding_side=\"left\",  # since HyenaDNA is causal, we pad on the left\n",
    ")\n",
    "\n",
    "model = HyenaDNAPreTrainedModel.from_pretrained(\n",
    "    os.path.join(EMBEDDER_DIR, EMBEDDER_NAME),\n",
    "    EMBEDDER_NAME,\n",
    "    download=not os.path.exists(EMBEDDER_DIR),\n",
    "    config=None,\n",
    "    device=device,\n",
    "    use_head=False,\n",
    "    use_lm_head=False,  # we don't use the LM head for embeddings\n",
    "    n_classes=2,\n",
    ").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec6cfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACATGTTCG',\n",
       " 'ACTTCGAGGATATG',\n",
       " 'CATAACTTT',\n",
       " 'TCTCT',\n",
       " 'TCATATGTC',\n",
       " 'TTGAGCTGAGGTCCG',\n",
       " 'GCTCAGCAAATAA',\n",
       " 'TCATCATCG',\n",
       " 'ATCGTGTGTGGGG',\n",
       " 'GCACAC']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [generate_random_dna_sequence(min_length=5, max_length=15) for _ in range(10)]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c52b25",
   "metadata": {},
   "source": [
    "#### Tokenise sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60673588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  4,  4,  4,  4,  4,  0,  7,  8,  7, 10,  9, 10, 10,  8,  9,  1],\n",
       "        [ 4,  0,  7,  8, 10, 10,  8,  9,  7,  9,  9,  7, 10,  7, 10,  9,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  0,  8,  7, 10,  7,  7,  8, 10, 10, 10,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  0, 10,  8, 10,  8, 10,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  0, 10,  8,  7, 10,  7, 10,  9, 10,  8,  1],\n",
       "        [ 0, 10, 10,  9,  7,  9,  8, 10,  9,  7,  9,  9, 10,  8,  8,  9,  1],\n",
       "        [ 4,  4,  0,  9,  8, 10,  8,  7,  9,  8,  7,  7,  7, 10,  7,  7,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  0, 10,  8,  7, 10,  8,  7, 10,  8,  9,  1],\n",
       "        [ 4,  4,  0,  7, 10,  8,  9, 10,  9, 10,  9, 10,  9,  9,  9,  9,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  0,  9,  8,  7,  8,  7,  8,  1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer(\n",
    "    sequences,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    padding=\"longest\",\n",
    ")\n",
    "\n",
    "input_ids = output[\"input_ids\"]\n",
    "attention_mask = output[\"attention_mask\"]\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ec0961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'A', 'C', 'A', 'T', 'G', 'T', 'T', 'C', 'G', '[SEP]']\n",
      "['[PAD]', '[CLS]', 'A', 'C', 'T', 'T', 'C', 'G', 'A', 'G', 'G', 'A', 'T', 'A', 'T', 'G', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'C', 'A', 'T', 'A', 'A', 'C', 'T', 'T', 'T', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'T', 'C', 'T', 'C', 'T', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'T', 'C', 'A', 'T', 'A', 'T', 'G', 'T', 'C', '[SEP]']\n",
      "['[CLS]', 'T', 'T', 'G', 'A', 'G', 'C', 'T', 'G', 'A', 'G', 'G', 'T', 'C', 'C', 'G', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[CLS]', 'G', 'C', 'T', 'C', 'A', 'G', 'C', 'A', 'A', 'A', 'T', 'A', 'A', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'T', 'C', 'A', 'T', 'C', 'A', 'T', 'C', 'G', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[CLS]', 'A', 'T', 'C', 'G', 'T', 'G', 'T', 'G', 'T', 'G', 'G', 'G', 'G', '[SEP]']\n",
      "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[CLS]', 'G', 'C', 'A', 'C', 'A', 'C', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "for ids in input_ids:\n",
    "    print(tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93db1e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8277f",
   "metadata": {},
   "source": [
    "#### Embed sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f95ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 17, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.LongTensor(input_ids)\n",
    "\n",
    "embeddings = model(input_ids=input_ids.to(device)).detach().cpu()\n",
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "523f6980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1129,  1.1244,  0.4640,  0.2453,  0.1486,  0.7546,  0.2239,  0.0606,\n",
       "         0.1209,  0.8705])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:, -1, -1]  # last token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7bfc1",
   "metadata": {},
   "source": [
    "#### Remove special tokens and stack into batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([9, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([14, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([9, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([5, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([9, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([15, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([13, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([9, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([13, 128])\n",
      "Embedding size:  torch.Size([17, 128])\n",
      "Masked emb size after postprocessing:  torch.Size([6, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Padding is on the left side, hence the need to remove it, then apply padding on the right side.\n",
    "# Also, removes special tokens like [CLS] and [SEP].\n",
    "\n",
    "masked_embeddings = []\n",
    "\n",
    "for ids, emb in zip(input_ids, embeddings):\n",
    "    print('Embedding size: ', emb.size())\n",
    "    masked_emb = remove_special_tokens_and_padding(tokenizer, ids, emb)\n",
    "    print('Masked emb size after postprocessing: ', masked_emb.size())\n",
    "    masked_embeddings.append(masked_emb)\n",
    "\n",
    "masked_embeddings = torch.nn.utils.rnn.pad_sequence(\n",
    "        masked_embeddings, batch_first=True, padding_value=PADDING_VALUE)\n",
    "masked_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f7f7d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "        -2.0537e-02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings[:, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63878ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
