{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "521d59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from utils import generate_random_dna_sequence, get_device, process_chunk_embeddings, chunkify_sequences\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDER_PATH = 'InstaDeepAI/nucleotide-transformer-2.5b-1000g'\n",
    "\n",
    "PADDING_VALUE = -100\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f38af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgreco2/miniconda3/envs/bend/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/dgreco2/miniconda3/envs/bend/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b943ffd98c94957b174669543c3ed54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgreco2/miniconda3/envs/bend/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(EMBEDDER_PATH).eval().to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec6cfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGGATCAGCA',\n",
       " 'CTTGGTCCGCCACG',\n",
       " 'CTTGCCC',\n",
       " 'AAACTTCGAAC',\n",
       " 'TTTAT',\n",
       " 'TCTGAGT',\n",
       " 'ACATAGGGAT',\n",
       " 'AAAATTG',\n",
       " 'TTCGGGTCAACGGT',\n",
       " 'ACAGTGGT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [generate_random_dna_sequence(min_length=5, max_length=15) for _ in range(10)]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e506cfe",
   "metadata": {},
   "source": [
    "#### Chunkify sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31253eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk ID: 0, Sequence: AGGA\n",
      "Chunk ID: 0, Sequence: TCAG\n",
      "Chunk ID: 0, Sequence: CA\n",
      "Chunk ID: 1, Sequence: CTTG\n",
      "Chunk ID: 1, Sequence: GTCC\n",
      "Chunk ID: 1, Sequence: GCCA\n",
      "Chunk ID: 1, Sequence: CG\n",
      "Chunk ID: 2, Sequence: CTTG\n",
      "Chunk ID: 2, Sequence: CCC\n",
      "Chunk ID: 3, Sequence: AAAC\n",
      "Chunk ID: 3, Sequence: TTCG\n",
      "Chunk ID: 3, Sequence: AAC\n",
      "Chunk ID: 4, Sequence: TTTA\n",
      "Chunk ID: 4, Sequence: T\n",
      "Chunk ID: 5, Sequence: TCTG\n",
      "Chunk ID: 5, Sequence: AGT\n",
      "Chunk ID: 6, Sequence: ACAT\n",
      "Chunk ID: 6, Sequence: AGGG\n",
      "Chunk ID: 6, Sequence: AT\n",
      "Chunk ID: 7, Sequence: AAAA\n",
      "Chunk ID: 7, Sequence: TTG\n",
      "Chunk ID: 8, Sequence: TTCG\n",
      "Chunk ID: 8, Sequence: GGTC\n",
      "Chunk ID: 8, Sequence: AACG\n",
      "Chunk ID: 8, Sequence: GT\n",
      "Chunk ID: 9, Sequence: ACAG\n",
      "Chunk ID: 9, Sequence: TGGT\n"
     ]
    }
   ],
   "source": [
    "MAX_MODEL_LENGTH = 4\n",
    "chunked_sequences, chunk_ids = chunkify_sequences(sequences, MAX_MODEL_LENGTH)\n",
    "\n",
    "for seq, chunk_id in zip(chunked_sequences, chunk_ids):\n",
    "    print(f\"Chunk ID: {chunk_id}, Sequence: {seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c52b25",
   "metadata": {},
   "source": [
    "#### Tokenise sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60673588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   3, 4100, 4103, 4103, 4100],\n",
       "        [   3, 4101, 4102, 4100, 4103],\n",
       "        [   3, 4102, 4100,    1,    1],\n",
       "        [   3, 4102, 4101, 4101, 4103],\n",
       "        [   3, 4103, 4101, 4102, 4102],\n",
       "        [   3, 4103, 4102, 4102, 4100],\n",
       "        [   3, 4102, 4103,    1,    1],\n",
       "        [   3, 4102, 4101, 4101, 4103],\n",
       "        [   3, 4102, 4102, 4102,    1],\n",
       "        [   3, 4100, 4100, 4100, 4102],\n",
       "        [   3, 4101, 4101, 4102, 4103],\n",
       "        [   3, 4100, 4100, 4102,    1],\n",
       "        [   3, 4101, 4101, 4101, 4100],\n",
       "        [   3, 4101,    1,    1,    1],\n",
       "        [   3, 4101, 4102, 4101, 4103],\n",
       "        [   3, 4100, 4103, 4101,    1],\n",
       "        [   3, 4100, 4102, 4100, 4101],\n",
       "        [   3, 4100, 4103, 4103, 4103],\n",
       "        [   3, 4100, 4101,    1,    1],\n",
       "        [   3, 4100, 4100, 4100, 4100],\n",
       "        [   3, 4101, 4101, 4103,    1],\n",
       "        [   3, 4101, 4101, 4102, 4103],\n",
       "        [   3, 4103, 4103, 4101, 4102],\n",
       "        [   3, 4100, 4100, 4102, 4103],\n",
       "        [   3, 4103, 4101,    1,    1],\n",
       "        [   3, 4100, 4102, 4100, 4103],\n",
       "        [   3, 4101, 4103, 4103, 4101]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer(\n",
    "    chunked_sequences,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    padding=\"longest\",\n",
    ")\n",
    "\n",
    "input_ids = output[\"input_ids\"]\n",
    "attention_mask = output[\"attention_mask\"]\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2903684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<cls>', 'A', 'G', 'G', 'A']\n",
      "['<cls>', 'T', 'C', 'A', 'G']\n",
      "['<cls>', 'C', 'A', '<pad>', '<pad>']\n",
      "['<cls>', 'C', 'T', 'T', 'G']\n",
      "['<cls>', 'G', 'T', 'C', 'C']\n",
      "['<cls>', 'G', 'C', 'C', 'A']\n",
      "['<cls>', 'C', 'G', '<pad>', '<pad>']\n",
      "['<cls>', 'C', 'T', 'T', 'G']\n",
      "['<cls>', 'C', 'C', 'C', '<pad>']\n",
      "['<cls>', 'A', 'A', 'A', 'C']\n",
      "['<cls>', 'T', 'T', 'C', 'G']\n",
      "['<cls>', 'A', 'A', 'C', '<pad>']\n",
      "['<cls>', 'T', 'T', 'T', 'A']\n",
      "['<cls>', 'T', '<pad>', '<pad>', '<pad>']\n",
      "['<cls>', 'T', 'C', 'T', 'G']\n",
      "['<cls>', 'A', 'G', 'T', '<pad>']\n",
      "['<cls>', 'A', 'C', 'A', 'T']\n",
      "['<cls>', 'A', 'G', 'G', 'G']\n",
      "['<cls>', 'A', 'T', '<pad>', '<pad>']\n",
      "['<cls>', 'A', 'A', 'A', 'A']\n",
      "['<cls>', 'T', 'T', 'G', '<pad>']\n",
      "['<cls>', 'T', 'T', 'C', 'G']\n",
      "['<cls>', 'G', 'G', 'T', 'C']\n",
      "['<cls>', 'A', 'A', 'C', 'G']\n",
      "['<cls>', 'G', 'T', '<pad>', '<pad>']\n",
      "['<cls>', 'A', 'C', 'A', 'G']\n",
      "['<cls>', 'T', 'G', 'G', 'T']\n"
     ]
    }
   ],
   "source": [
    "for ids in input_ids:\n",
    "    print(tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93db1e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636feaf",
   "metadata": {},
   "source": [
    "#### Embed Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a25410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 5, 2560)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), output_hidden_states=True,)[\"hidden_states\"][-1].detach().cpu().numpy()\n",
    "input_ids = input_ids.numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b134a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3886814e-01,  4.3697691e-01, -8.8939840e-01,  9.9667683e-03,\n",
       "       -6.8073377e-02, -2.1069090e-01, -5.8168566e-01,  9.9667683e-03,\n",
       "       -1.4776534e-01,  2.7478859e-01,  4.4103006e-01, -5.8178532e-01,\n",
       "        2.4884179e-01, -2.9568106e-01,  1.4081374e-01, -6.2673521e-01,\n",
       "        2.8391942e-01, -2.2443391e-02, -5.6441110e-01,  6.5617457e-02,\n",
       "       -5.0080180e-01,  4.4103006e-01, -2.9559991e-01, -4.8437916e-02,\n",
       "       -7.2403973e-01,  4.3183891e-04,  3.2815367e-01], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:, -1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d6717",
   "metadata": {},
   "source": [
    "#### Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d882627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk ID: 0\n",
      "Sequence: AGGATCAGCA  Length: 10\n",
      "  Tokens: AGGATCAGCA\n",
      "Embedding shape: (10, 2560)\n",
      "Chunk ID: 1\n",
      "Sequence: CTTGGTCCGCCACG  Length: 14\n",
      "  Tokens: CTTGGTCCGCCACG\n",
      "Embedding shape: (14, 2560)\n",
      "Chunk ID: 2\n",
      "Sequence: CTTGCCC  Length: 7\n",
      "  Tokens: CTTGCCC\n",
      "Embedding shape: (7, 2560)\n",
      "Chunk ID: 3\n",
      "Sequence: AAACTTCGAAC  Length: 11\n",
      "  Tokens: AAACTTCGAAC\n",
      "Embedding shape: (11, 2560)\n",
      "Chunk ID: 4\n",
      "Sequence: TTTAT  Length: 5\n",
      "  Tokens: TTTAT\n",
      "Embedding shape: (5, 2560)\n",
      "Chunk ID: 5\n",
      "Sequence: TCTGAGT  Length: 7\n",
      "  Tokens: TCTGAGT\n",
      "Embedding shape: (7, 2560)\n",
      "Chunk ID: 6\n",
      "Sequence: ACATAGGGAT  Length: 10\n",
      "  Tokens: ACATAGGGAT\n",
      "Embedding shape: (10, 2560)\n",
      "Chunk ID: 7\n",
      "Sequence: AAAATTG  Length: 7\n",
      "  Tokens: AAAATTG\n",
      "Embedding shape: (7, 2560)\n",
      "Chunk ID: 8\n",
      "Sequence: TTCGGGTCAACGGT  Length: 14\n",
      "  Tokens: TTCGGGTCAACGGT\n",
      "Embedding shape: (14, 2560)\n",
      "Chunk ID: 9\n",
      "Sequence: ACAGTGGT  Length: 8\n",
      "  Tokens: ACAGTGGT\n",
      "Embedding shape: (8, 2560)\n"
     ]
    }
   ],
   "source": [
    "sequence_embeddings, masked_tokens = process_chunk_embeddings(tokenizer, embeddings, input_ids, chunk_ids, upsample=True)\n",
    "\n",
    "for i, seq_emb in enumerate(sequence_embeddings):\n",
    "    assert sequences[i] == ''.join(masked_tokens[i]), f\"Mismatch in sequence {i}: {sequences[i]} != {''.join(masked_tokens[i])}\"\n",
    "    print(f\"Chunk ID: {np.unique(chunk_ids)[i]}\")\n",
    "    print(f\"Sequence: {sequences[i]}  Length: {len(sequences[i])}\")\n",
    "    print(f\"  Tokens: {''.join(masked_tokens[i])}\")\n",
    "    print(f\"Embedding shape: {seq_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f97da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2402e-01, -1.0000e+02, -3.7545e-02, -1.0000e+02, -3.3865e-01,\n",
       "        -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_embeddings[:, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961833cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
